<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <title>guanyu.html</title>
	
    <meta http-equiv="keywords" content="keyword1,keyword2,keyword3">
    <meta http-equiv="description" content="this is my page">
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    
    <!--<link rel="stylesheet" type="text/css" href="./styles.css">-->

  </head>
  
  <body>
    <pre>
	非常感谢关注搜天下！
	-----------------------------------------------------------------------------------------
	项目名称：通用全文搜索引擎(General Search Engine)
	称    谓：搜天下！(stx)
	研 发 者：北大青鸟.重庆足下中心.07081T.陈建宇
	开发周期：4个月(2008.11-2009.3)
	-----------------------------------------------------------------------------------------
	项目概述：
	1.数量超过130万的精心整理的词条，包揽社会各个行业、特别是对于数学、物理学、化学、生物学、医学、电子、
	  机械、工程、软件等有较强的检索能力。
	2.先进高效的中文分词算法，支持对单个字符和超长短句的检索，最长检索量已达18字符（百度为28）。
	3.采用二次分词比较策略和基于词频统计的中心语提取算法，提高了检索精度。
	4.采用了多级倒排索引、高速缓存、多线程同时检索等技术有效地提高了检索效率，检索用时不超过0.5秒。
	5.目前只支持对网页信息的搜索。
	6.支持对少量英文、少量中文繁体、少数特殊字符的检索。
	7.具有一定的内容分析判断能力，能排除部分无实际价值的网页信息（如网页广告、垃圾信息、灌水文章等）提高了
	  检索实用性和准确性。
	8.由于硬件和网络带宽的限制，对数据采集被迫使用单进程多线程采集模式。
	9.蜘蛛程序采用了多线程智能调度机制。
	10.多线程同时抓取网页，由于服务器带宽限制，最多支持10个线程同时运行，一运行整个局域网卡得要命。
	11.对网页的抓取采用了广度优先和深度无限策略，分批次抓取，分时段抓取。
	12.支持对UTF-8、GBK、GB2312编码格式的网页进行抓取。
	14.暂不支持框架网页。
	15.支持对超链接路劲的解析，有相对路径到绝对路径的转换、去除无效链接等较强的筛选能力，支持所有动态URL。
	16.十分重视网页标题和网页内容的相关程度。
	17.不对javascript脚本进行解析。
	18.采用了无损压缩技术存储数据，节约存储空间。
	19.提供强大的二次开发接口，可随意扩展业务。
	20.纯JAVA内核。
	-----------------------------------------------------------------------------------------
	服务器硬件性能：
	处理器：Intel E2140 1.6GHZ
	内存：1GB DDR2 667
	硬盘：SATA 7200转/s 80GB
	网络环境：电信ADSL 1MB 内网 端口映射

	服务器软件环境：
	Windows XP SP3
	JDK1.6
	Apache-Tomcat6.0
	-----------------------------------------------------------------------------------------
	感言：
	    终于把这个令人头痛的项目做完了，终于在2008-2009年中有所突破，终于在漫漫技术路上写下了辉煌的一页。
	通过做搜索引擎，我学到了很多知识，那不仅仅是计算机语言，更大程度上是在设计和业务逻辑的处理上。搜索引擎
	非同一般的站内检索，关系型数据库对数据的复杂逻辑满足不了搜索引擎对信息检索的基本要求：快、准、多。搜索
	引擎必须根据业务需求，自行设计特殊的数据库和检索模块，它要解决的根本问题是：在海量数据中，高速检索准确
	的，相关度大的数据。检索效率要比关系型数据库高N倍以上，N不确切是因为不同的关系数据库的效率不一样，N可
	以是10，也可以是100。在项目构思时，我的最低要求是要达到每次检索时间最长不超过0.5秒，而实际上还不到0.1
	秒，大多数情况下在0.001-0.060之间，在预期的情况下提高了几十倍。这样的数据库设计是有难度的。检索模块
	包括对用户输入的短句分词、索引定位、文档读取、数据归类、结果排序等一系列复杂业务。作为用户提交检索请求
	的入口，检索器必须非常高效！要在几十毫秒的时间下完成分词、找数据、排序、返回等动作，是十分不易的，要达到
	这个目的，必须在设计上和算法上深入研究。解决了数据库系统和检索系统，接着就是数据采集系统了，采集系统不要
	求有太高的效率，质量才是核心，本搜索引擎由于受到硬件条件限制，采用了单进程多线程模式。HTTP协议的灵活性
	和万维网的分布方式以及互联网数据类别的多元化给采集系统带来了不少麻烦，面临一系列问题，每个问题都必须得到
	解决，只要疏忽其中一个环节，整个采集系统就可能陷入瘫痪。在做整个项目的时候，我花在采集系统的时间大于其他
	所有模块的时间的总和。网页代码的凌乱、HTTP状态、数据传输方式、数据编码格式、对抓取的页面的解析等等等等
	都是难题，以前也从为遇到过这类题目。总之独自完成这个系统，它不是那么容易的事。目前本系统问题多多，错误多
	多，但是它会不断改进与完善。
	    有志者，事竟成；破釜沉舟，百二秦关终归楚。
	    苦心人，天不负；卧薪尝胆，三千越甲可吞吴。
	    										2009-3-31
	    										陈建宇
	-----------------------------------------------------------------------------------------
	联系方式：
		E-mail:lnux@163.com
		QQ:377122912(绝对实力)
		
	信息检索研究QQ群：46684272
	本群致力于互联网信息检索技术研究，为广大爱好搜索引擎技术的朋友提供交流平台和技术支持。
	
    
    </pre>
  </body>
</html>
